{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_gen.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_gen.py\n",
    "import os, glob, cv2, math, csv, tqdm, random\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_image(image_path):\n",
    "    return cv2.resize(np.array(Image.open(image_path)), (416,128))/255.\n",
    "        \n",
    "def augment_image_colorspace(image):\n",
    "    # input shape [h, w * seq , c]\n",
    "    random_gamma = random.uniform(0.8,1.2)\n",
    "    random_brightness = random.uniform(0.5, 2.0)\n",
    "    random_colors = [random.uniform(0.8,1.2), random.uniform(0.8,1.2), random.uniform(0.8,1.2)]\n",
    "    # Randomly shift gamma.\n",
    "    image_aug = image**random_gamma\n",
    "    # Randomly shift brightness. \n",
    "    image_aug *= random_brightness\n",
    "    # Randomly shift color. \n",
    "    white = np.ones([image.shape[0], image.shape[1]])\n",
    "    color_image = np.stack([white * random_colors[i] for i in range(3)], axis=2)\n",
    "    image_aug *= color_image\n",
    "    # Saturate.\n",
    "    image_aug = np.clip(image_aug, 0, 1)\n",
    "    return image_aug\n",
    "\n",
    "def pack_images_width(img1, img2, img3):\n",
    "    return np.concatenate((img1,img2,img3), axis=1)\n",
    "\n",
    "def unpack_images_stack(image_seq):\n",
    "    width = np.int(image_seq.shape[1]/3)\n",
    "    img1_f = np.concatenate((image_seq[:,:width,:],image_seq[:,width:width *2,:]), axis = 2)\n",
    "    img2_f = np.concatenate((image_seq[:,width:width *2,:],image_seq[:,width *2:,:]), axis = 2)\n",
    "    img1_b = np.concatenate((image_seq[:,width *2:,:],image_seq[:,width:width *2,:]), axis = 2)\n",
    "    img2_b = np.concatenate((image_seq[:,width:width *2,:],image_seq[:,:width,:]), axis = 2)\n",
    "    return img1_f, img2_f, img1_b, img2_b\n",
    "\n",
    "def dataset_list_loader(kitti_path):\n",
    "    dir_lists = sorted(os.listdir(kitti_path))\n",
    "    total = []\n",
    "    for i in dir_lists:\n",
    "        paths = sorted(glob.glob(kitti_path + i + '/image_02/data/*.png'))\n",
    "        x = [[paths[i], paths[i+1], paths[i+2]] for i in range(len(paths)-2)]\n",
    "        for j in x:\n",
    "            total.append(j)          \n",
    "    return total\n",
    "\n",
    "def img_aug_total(img_path):\n",
    "    img_concat = pack_images_width(read_image(img_path[0]), read_image(img_path[1]), read_image(img_path[2]))\n",
    "    return unpack_images_stack(augment_image_colorspace(img_concat))\n",
    "\n",
    "def data_generator(total_img, batch):\n",
    "    total = []\n",
    "    random.shuffle(total_img)\n",
    "    idx = 0\n",
    "    while 1:   \n",
    "        bat_img = []\n",
    "        if idx > len(total_img) - batch:\n",
    "            tmp_path = total_img[idx:]\n",
    "            idx = 0\n",
    "        else:\n",
    "            tmp_path = total_img[idx:idx+16]\n",
    "            idx = idx + batch\n",
    "\n",
    "        for i in tmp_path:\n",
    "            img1, img2, img3, img4 = img_aug_total(i)\n",
    "            bat_img.append(img1)\n",
    "            bat_img.append(img2)\n",
    "            bat_img.append(img3)\n",
    "            bat_img.append(img4)\n",
    "        \n",
    "        yield np.array(bat_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reader.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reader.py\n",
    "import os\n",
    "import random\n",
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "import util\n",
    "\n",
    "gfile = tf.gfile\n",
    "\n",
    "QUEUE_SIZE = 2000\n",
    "QUEUE_BUFFER = 3\n",
    "\n",
    "\n",
    "class DataReader(object):\n",
    "    # Reads stored sequences which are produced by dataset/gen_data.py.\n",
    "    def __init__(self, data_dir, batch_size, img_height, img_width, seq_length, num_scales):\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.seq_length = seq_length\n",
    "        self.num_scales = num_scales\n",
    "\n",
    "    def read_data(self):\n",
    "        # Provides images and camera intrinsics.\n",
    "        with tf.name_scope('data_loading'):\n",
    "            with tf.name_scope('enqueue_paths'):\n",
    "                seed = random.randint(0, 2**31 - 1)\n",
    "                self.file_lists = self.compile_file_list(self.data_dir, 'train')\n",
    "                image_paths_queue = tf.train.string_input_producer(self.file_lists['image_file_list'], seed=seed, shuffle=True)\n",
    "                cam_paths_queue = tf.train.string_input_producer(self.file_lists['cam_file_list'], seed=seed, shuffle=True)\n",
    "                img_reader = tf.WholeFileReader()\n",
    "                _, image_contents = img_reader.read(image_paths_queue)\n",
    "                image_seq = tf.image.decode_jpeg(image_contents)\n",
    "\n",
    "            with tf.name_scope('load_intrinsics'):\n",
    "                cam_reader = tf.TextLineReader()\n",
    "                _, raw_cam_contents = cam_reader.read(cam_paths_queue)\n",
    "                rec_def = []\n",
    "            for _ in range(9):\n",
    "                rec_def.append([1.0])\n",
    "                raw_cam_vec = tf.decode_csv(raw_cam_contents, record_defaults=rec_def)\n",
    "                raw_cam_vec = tf.stack(raw_cam_vec)\n",
    "                intrinsics = tf.reshape(raw_cam_vec, [3, 3])\n",
    "\n",
    "            with tf.name_scope('convert_image'):\n",
    "                image_seq = self.preprocess_image(image_seq)  # Converts to float.\n",
    "\n",
    "            with tf.name_scope('image_augmentation'):\n",
    "                image_seq = self.augment_image_colorspace(image_seq)\n",
    "\n",
    "            image_stack = self.unpack_images(image_seq)\n",
    "\n",
    "            with tf.name_scope('image_augmentation_scale_crop'):\n",
    "                image_stack, intrinsics = self.augment_images_scale_crop(image_stack, intrinsics, self.img_height, self.img_width)\n",
    "\n",
    "            with tf.name_scope('multi_scale_intrinsics'):\n",
    "                intrinsic_mat = self.get_multi_scale_intrinsics(intrinsics, self.num_scales)\n",
    "                intrinsic_mat.set_shape([self.num_scales, 3, 3])\n",
    "                intrinsic_mat_inv = tf.matrix_inverse(intrinsic_mat)\n",
    "                intrinsic_mat_inv.set_shape([self.num_scales, 3, 3])\n",
    "\n",
    "            with tf.name_scope('batching'):\n",
    "                image_stack, intrinsic_mat, intrinsic_mat_inv = (\n",
    "                    tf.train.shuffle_batch(\n",
    "                        [image_stack, intrinsic_mat, intrinsic_mat_inv],\n",
    "                        batch_size=self.batch_size,\n",
    "                        capacity=QUEUE_SIZE + QUEUE_BUFFER * self.batch_size,\n",
    "                        min_after_dequeue=QUEUE_SIZE))\n",
    "        return image_stack, intrinsic_mat, intrinsic_mat_inv\n",
    "\n",
    "    def unpack_images(self, image_seq):\n",
    "        #[h, w * seq_length, 3] -> [h, w, 3 * seq_length].\n",
    "        with tf.name_scope('unpack_images'):\n",
    "            image_list = [image_seq[:, i * self.img_width:(i + 1) * self.img_width, :]for i in range(self.seq_length)]\n",
    "            image_stack = tf.concat(image_list, axis=2)\n",
    "            image_stack.set_shape(\n",
    "            [self.img_height, self.img_width, self.seq_length * 3])\n",
    "            return image_stack\n",
    "\n",
    "    @classmethod\n",
    "    def preprocess_image(cls, image):\n",
    "        # Convert from uint8 to float.\n",
    "        return tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "\n",
    "  # Source: https://github.com/mrharicot/monodepth.\n",
    "    @classmethod\n",
    "    def augment_image_colorspace(cls, image_seq):\n",
    "        # Apply data augmentation to inputs.\"\"\"\n",
    "        # Randomly shift gamma.\n",
    "        random_gamma = tf.random_uniform([], 0.8, 1.2)\n",
    "        image_seq_aug = image_seq**random_gamma\n",
    "        # Randomly shift brightness.\n",
    "        random_brightness = tf.random_uniform([], 0.5, 2.0)\n",
    "        image_seq_aug *= random_brightness\n",
    "        # Randomly shift color.\n",
    "        random_colors = tf.random_uniform([3], 0.8, 1.2)\n",
    "        white = tf.ones([tf.shape(image_seq)[0], tf.shape(image_seq)[1]])\n",
    "        color_image = tf.stack([white * random_colors[i] for i in range(3)], axis=2)\n",
    "        image_seq_aug *= color_image\n",
    "        # Saturate.\n",
    "        image_seq_aug = tf.clip_by_value(image_seq_aug, 0, 1)\n",
    "        return image_seq_aug\n",
    "\n",
    "    @classmethod\n",
    "    def augment_images_scale_crop(cls, im, intrinsics, out_h, out_w):\n",
    "    #Randomly scales and crops image.\n",
    "\n",
    "        def scale_randomly(im, intrinsics):\n",
    "            #Scales image and adjust intrinsics accordingly.\n",
    "            in_h, in_w, _ = im.get_shape().as_list()\n",
    "            scaling = tf.random_uniform([2], 1, 1.15)\n",
    "            x_scaling = scaling[0]\n",
    "            y_scaling = scaling[1]\n",
    "            out_h = tf.cast(in_h * y_scaling, dtype=tf.int32)\n",
    "            out_w = tf.cast(in_w * x_scaling, dtype=tf.int32)\n",
    "            # Add batch.\n",
    "            im = tf.expand_dims(im, 0)\n",
    "            im = tf.image.resize_area(im, [out_h, out_w])\n",
    "            im = im[0]\n",
    "            fx = intrinsics[0, 0] * x_scaling\n",
    "            fy = intrinsics[1, 1] * y_scaling\n",
    "            cx = intrinsics[0, 2] * x_scaling\n",
    "            cy = intrinsics[1, 2] * y_scaling\n",
    "            intrinsics = cls.make_intrinsics_matrix(fx, fy, cx, cy)\n",
    "            return im, intrinsics\n",
    "\n",
    "        # Random cropping\n",
    "        def crop_randomly(im, intrinsics, out_h, out_w):\n",
    "            #Crops image and adjust intrinsics accordingly.\n",
    "            # batch_size, in_h, in_w, _ = im.get_shape().as_list()\n",
    "            in_h, in_w, _ = tf.unstack(tf.shape(im))\n",
    "            offset_y = tf.random_uniform([1], 0, in_h - out_h + 1, dtype=tf.int32)[0]\n",
    "            offset_x = tf.random_uniform([1], 0, in_w - out_w + 1, dtype=tf.int32)[0]\n",
    "            im = tf.image.crop_to_bounding_box(im, offset_y, offset_x, out_h, out_w)\n",
    "            fx = intrinsics[0, 0]\n",
    "            fy = intrinsics[1, 1]\n",
    "            cx = intrinsics[0, 2] - tf.cast(offset_x, dtype=tf.float32)\n",
    "            cy = intrinsics[1, 2] - tf.cast(offset_y, dtype=tf.float32)\n",
    "            intrinsics = cls.make_intrinsics_matrix(fx, fy, cx, cy)\n",
    "            return im, intrinsics\n",
    "\n",
    "        im, intrinsics = scale_randomly(im, intrinsics)\n",
    "        im, intrinsics = crop_randomly(im, intrinsics, out_h, out_w)\n",
    "        return im, intrinsics\n",
    "\n",
    "    def compile_file_list(self, data_dir, split, load_pose=False):\n",
    "        # Creates a list of input files.\n",
    "        with gfile.Open(os.path.join(data_dir, '%s.txt' % split), 'r') as f:\n",
    "            frames = f.readlines()\n",
    "        subfolders = [x.split(' ')[0] for x in frames]\n",
    "        frame_ids = [x.split(' ')[1][:-1] for x in frames]\n",
    "        image_file_list = [os.path.join(data_dir, subfolders[i], frame_ids[i] + '.jpg') for i in range(len(frames))]\n",
    "        cam_file_list = [os.path.join(data_dir, subfolders[i], frame_ids[i] + '_cam.txt') for i in range(len(frames))]\n",
    "        file_lists = {}\n",
    "        file_lists['image_file_list'] = image_file_list\n",
    "        file_lists['cam_file_list'] = cam_file_list\n",
    "        if load_pose:\n",
    "            pose_file_list = [os.path.join(data_dir, subfolders[i], frame_ids[i] + '_pose.txt') for i in range(len(frames))]\n",
    "        file_lists['pose_file_list'] = pose_file_list\n",
    "        self.steps_per_epoch = len(image_file_list) // self.batch_size\n",
    "        return file_lists\n",
    "\n",
    "    @classmethod\n",
    "    def make_intrinsics_matrix(cls, fx, fy, cx, cy):\n",
    "        r1 = tf.stack([fx, 0, cx])\n",
    "        r2 = tf.stack([0, fy, cy])\n",
    "        r3 = tf.constant([0., 0., 1.])\n",
    "        intrinsics = tf.stack([r1, r2, r3])\n",
    "        return intrinsics\n",
    "\n",
    "    @classmethod\n",
    "    def get_multi_scale_intrinsics(cls, intrinsics, num_scales):\n",
    "        #Returns multiple intrinsic matrices for different scales.\n",
    "        intrinsics_multi_scale = []\n",
    "        # Scale the intrinsics accordingly for each scale\n",
    "        for s in range(num_scales):\n",
    "            fx = intrinsics[0, 0] / (2**s)\n",
    "            fy = intrinsics[1, 1] / (2**s)\n",
    "            cx = intrinsics[0, 2] / (2**s)\n",
    "            cy = intrinsics[1, 2] / (2**s)\n",
    "            intrinsics_multi_scale.append(cls.make_intrinsics_matrix(fx, fy, cx, cy))\n",
    "        intrinsics_multi_scale = tf.stack(intrinsics_multi_scale)\n",
    "        return intrinsics_multi_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2147483647"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**31 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
